# Generative AI for Business Applications (PGP-GABA)

<div align="center">

![McCombs School](https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png)

**A Comprehensive Learning Repository**  
*McCombs School of Business √ó Great Learning*

</div>

---

## üìö Overview

This repository contains a complete educational curriculum for **Generative AI for Business Applications**, featuring 50+ hands-on Jupyter notebooks covering Python fundamentals, machine learning, deep learning, NLP, and cutting-edge GenAI techniques. The materials are designed for progressive learning, from beginner Python concepts to advanced agentic AI systems.

## üéØ Learning Path

### **Phase 1: Python & Data Science Foundations**

#### Python Fundamentals
- **`02_PGP_GABA_Getting_Started_with_Python.ipynb`**
  - Variables, data types, and operators
  - Control flow (if/else, loops)
  - Functions and error handling
  - Business case: WOW Superstore analytics

#### NumPy & Numerical Computing
- **`Understanding_NumPy_An_Introduction.ipynb`**
- **`Hands_on_Notebook_NumPy_additional.ipynb`**
- **`PythonForDataScience_intro.ipynb`** / **`PythonForDataScience_intro_additional.ipynb`**
  - Array operations and broadcasting
  - Linear algebra and statistical functions
  - Performance optimization techniques

#### Pandas & Data Manipulation
- **`Pandas_The_Data_Powerhouse_of_Python.ipynb`**
- **`Hands_on_Notebook_Pandas.ipynb`** / **`Hands_on_Notebook_Pandas_additional.ipynb`**
  - DataFrames and Series operations
  - Data cleaning and transformation
  - Aggregation and grouping
  - Time series analysis

**Key Teaching Points:**
- Vectorized operations for performance
- Data wrangling best practices
- Real-world data preprocessing workflows

---

### **Phase 2: Machine Learning & Neural Networks**

#### Classical Machine Learning
- **`Linear_Regression.ipynb`**
  - Model training and evaluation
  - Feature engineering
  - Hypothesis testing

#### Neural Networks Introduction
- **`Week_2_Hands_on_Introduction_to_Neural_Networks_Notebook.ipynb`**
  - Perceptrons and activation functions
  - Backpropagation fundamentals
  - Multi-layer architectures
  - Keras/TensorFlow implementation

#### Industry Case Studies

**Customer Analytics:**
- **`Case_Study_Customer_Churn_Prediction.ipynb`**
  - Binary classification
  - Feature importance analysis
  - Business impact metrics

**Financial Services:**
- **`Credit_Card_Fraud_Detection_Case_Study.ipynb`**
  - Imbalanced dataset handling
  - Precision vs. recall trade-offs
  - Real-time detection strategies

**Healthcare:**
- **`Case_Study_Health_Insurance_Premium_Prediction.ipynb`**
  - Regression modeling
  - Risk factor analysis
  - Actuarial applications

**Computer Vision:**
- **`Covid_19_Image_Classification.ipynb`**
  - Convolutional Neural Networks (CNNs)
  - Medical image processing
  - Transfer learning techniques

**Key Teaching Points:**
- Model selection and hyperparameter tuning
- Handling real-world data challenges
- Business metric alignment (ROI, cost-benefit analysis)

---

### **Phase 3: Natural Language Processing**

#### Sentiment Analysis Applications
- **`Airline_Customer_Sentiment_Analysis.ipynb`**
- **`Restaurant_Review_Analysis_Notebook.ipynb`** (+ GPT/TinyLlama variants)
- **`Case_Study_Product_Review_Sentiment_Analysis_Transformers.ipynb`**
  - Traditional NLP (TF-IDF, Word2Vec)
  - Transformer-based models (BERT, DistilBERT)
  - Multi-class classification
  - Real-time inference optimization

#### Text Classification
- **`Support_Ticket_Categorization.ipynb`** (+ GPT/TinyLlama variants)
  - Intent recognition
  - Multi-label classification
  - Active learning for labeling efficiency

#### Recommendation Systems
- **`Movie_Recommendation_system.ipynb`**
  - Collaborative filtering
  - Content-based filtering
  - Hybrid approaches

**Key Teaching Points:**
- Evolution from traditional NLP to transformers
- Model size vs. performance trade-offs
- Local model deployment (LM Studio integration)

---

### **Phase 4: Embeddings & Transformers**

#### Core Concepts
- **`Hands_on_Embeddings_to_Transformers.ipynb`**
  - Word embeddings (Word2Vec, GloVe, FastText)
  - Contextual embeddings (ELMo, BERT)
  - Attention mechanisms
  - Self-attention and multi-head attention
  - Positional encoding

- **`Hands_on_Transformers_for_Text_Generation.ipynb`**
  - GPT architecture
  - Encoder-decoder models
  - Autoregressive generation
  - Beam search and sampling strategies

**Key Teaching Points:**
- Transformer architecture deep dive
- Pre-training vs. fine-tuning paradigms
- Token-level vs. sequence-level tasks

---

### **Phase 5: Prompt Engineering**

#### Prompt Design Techniques
- **`Hands_on_Prompt_Engineering.ipynb`** (+ GPT/LM Studio variants)
  - Zero-shot, few-shot, and chain-of-thought prompting
  - Role-based prompting
  - Output formatting and constraints
  - Prompt templates and best practices
  - Temperature and token parameters
  - System vs. user vs. assistant messages

**Key Teaching Points:**
- Prompt engineering as a core skill
- Model behavior control
- Cost optimization through effective prompting

---

### **Phase 6: Advanced GenAI Techniques**

#### Retrieval-Augmented Generation (RAG)
- **`Hands_On_Notebook_RAG.ipynb`**
- **`fine_tuning_rag_aws_local.ipynb`**
  - Vector databases (ChromaDB, Pinecone)
  - Embedding-based retrieval
  - Context augmentation
  - Hybrid search strategies
  - RAG vs. fine-tuning trade-offs

#### Fine-Tuning LLMs
- **`Hands_on_Finetuning_with_LLMs.ipynb`** (Multiple variants for different environments)
- **`Additional Case Study Fine Tunning LLMs.ipynb`**
- **`Week11_MLS_FineTuning.ipynb`**
  - Parameter-efficient fine-tuning (PEFT)
  - LoRA (Low-Rank Adaptation)
  - Dataset preparation and formatting
  - Training loop and evaluation
  - Model versioning
  - Mac/local environment variants (Phi-3.5, GPT-OSS)

**Variants Available:**
- `Hands_on_Finetuning_with_LLMs_Fixed.ipynb` - Debugged version
- `Hands_on_Finetuning_with_LLMs_GPT.ipynb` - Cloud API version
- `Hands_on_Finetuning_with_LLMs_Mac_Claude.ipynb` - Mac-optimized
- `Hands_on_Finetuning_with_LLMs_Phi35_mini.ipynb` - Lightweight model

**Key Teaching Points:**
- When to fine-tune vs. prompt engineering vs. RAG
- Cost and computational considerations
- Domain adaptation strategies

---

### **Phase 7: Responsible AI & Guardrails**

#### Safety & Compliance
- **`Hands_On_Responsible_AI.ipynb`** (+ GPT-OSS variant)
  - Input validation and sanitization
  - Output filtering and content safety
  - Bias detection and mitigation
  - Explainability and transparency
  - Adversarial prompt detection
  - Ethical AI principles

**Key Teaching Points:**
- Production readiness requires guardrails
- Regulatory compliance (GDPR, CCPA, AI Act)
- Red teaming and security testing

---

### **Phase 8: Agentic AI & Production Systems**

#### Agentic AI Fundamentals
- **`agentic_AI_intro_hands_on.ipynb`**
  - Agent architectures (ReAct, Plan-and-Execute)
  - Tool calling and function execution
  - Multi-step reasoning
  - Memory and state management

#### Production Chatbots

**Low-Code Implementations:**
- **`FoodHub_Chatbot_LowCode_Notebook.ipynb`** (+ GPT-OSS variant)
  - LangChain AgentExecutor
  - Simple tool chains
  - Linear workflows
  - Quick prototyping

**Full-Code Implementations:**
- **`FoodHub_Chatbot_FullCode_Notebook.ipynb`** (+ GPT-OSS variant)
  - **LangGraph state machines**
  - Cyclical workflows and retry logic
  - Quality evaluation gates
  - Conversation memory (SQLite checkpointing)
  - Advanced guardrails (sentiment + urgency scoring)
  - Production logging and observability

**Healthcare Vertical:**
- **`Healthcare_Audit_Chatbot_Solution_Notebook.ipynb`**
  - HIPAA-compliant design patterns
  - Multi-step auditing workflows
  - Structured data extraction
  - Enterprise guardrails

**E-commerce Vertical:**
- **`Gen_AI_Application_Case_Study_Kartify_Order_Query_Chatbot.ipynb`**
- **`Project_1_Learner_Notebook_Low_Code.ipynb`**
- **`04_Learners_Notebook_Low_Code.ipynb`** / **`05_Learners_Notebook_Full_Code.ipynb`**
  - Order management integration
  - SQL database querying
  - Multi-turn conversations

**Key Teaching Points:**
- Linear vs. graph-based agent architectures
- When to use LangGraph vs. simpler alternatives
- Memory management strategies
- Error handling and retry mechanisms
- Production deployment considerations

#### Advanced Agentic Systems

**News & Research Assistants:**
- **`ACS_News_Finder_With_Guardrails.ipynb`**
- **`Smart_Research_Assistant.ipynb`**
- **`LLM_Powered_Research_Assistant.ipynb`**
- **`MLS_AI_Powered_Personalized_News_Discovery_Agent.ipynb`**
  - Web scraping and API integration
  - Multi-source information aggregation
  - Fact-checking and verification
  - Personalization engines

**Logistics & Operations:**
- **`ACS_Greatglobe_Logistics_Assistant.ipynb`**
  - Route optimization
  - Real-time decision making
  - Multi-agent coordination

**Multimodal AI:**
- **`Multimodal_GenerativeAI_Browbake_Case_Study_Notebook.ipynb`**
  - Vision-language models
  - Image understanding with text generation
  - Cross-modal retrieval

**Key Teaching Points:**
- Agent specialization and orchestration
- Tool integration patterns
- Real-world API constraints
- Cost optimization in production

---

## üõ†Ô∏è Technical Setup

### Environment Options

#### 1. Cloud-Based (Recommended for Beginners)
```bash
# Google Colab or Kaggle
# No local setup required
```

#### 2. Local Python Environment
```bash
# Create virtual environment
python -m venv jupyter_env
source jupyter_env/bin/activate  # On Mac/Linux
jupyter_env\Scripts\activate     # On Windows

# Install dependencies
pip install -r requirements.txt
```

#### 3. Local LLM Setup (Advanced)
See `GPT_OSS_SETUP_README.md` and `README_Mistral_Download.md` for:
- LM Studio installation
- Local model deployment (GPT-OSS 20B, Mistral, Phi-3.5)
- Mac-compatible model loading
- Performance optimization

**Helper Scripts:**
- `check_lighter_models.py` - Find compatible models for your hardware
- `mac_compatible_model_loading.py` - Mac-specific optimizations
- `model_info_builtin.py` - Query local model capabilities

---

## üìä Data Assets

The `data/` directory contains:
- **Customer order databases** (SQLite) for chatbot projects
- **CSV datasets** for ML case studies
- **Insurance/healthcare data** for sentiment analysis
- **Fine-tuning datasets** (training, validation, test splits)
- **Vector databases** (`chroma_db/`, `vectordb/`) for RAG
- **Streamlit app assets** (`streamlit_files/`)

---

## üéì Learning Outcomes

By completing these notebooks, you will:

1. **Master Python** for data science and AI development
2. **Build ML models** from scratch using NumPy, Pandas, and TensorFlow
3. **Understand NLP evolution** from bag-of-words to transformers
4. **Implement production RAG systems** with vector databases
5. **Fine-tune LLMs** for domain-specific tasks
6. **Design agentic AI systems** with tools and memory
7. **Apply responsible AI** principles and guardrails
8. **Deploy real-world applications** (chatbots, research assistants, sentiment analyzers)

---

## üìù Best Practices for Learning

### Sequential Learning Path
1. Start with Python fundamentals (Phase 1)
2. Build ML intuition with case studies (Phase 2)
3. Master NLP and transformers (Phases 3-4)
4. Learn prompt engineering before fine-tuning (Phase 5)
5. Explore advanced techniques (RAG, fine-tuning) (Phase 6)
6. Study responsible AI (Phase 7)
7. Build production systems (Phase 8)

### Hands-On Approach
- Run every code cell and experiment with parameters
- Modify business cases to your domain
- Compare model variants (GPT vs. local models)
- Implement guardrails for your use cases

### Project-Based Learning
- Start with Low-Code chatbot
- Enhance to Full-Code with LangGraph
- Add domain-specific guardrails
- Deploy with Streamlit (see `data/streamlit_files/`)

---

## üîß Repository Structure

```
PGP-GABA/
‚îú‚îÄ‚îÄ notebooks/           # 50+ educational Jupyter notebooks
‚îú‚îÄ‚îÄ data/               # Datasets and databases
‚îÇ   ‚îú‚îÄ‚îÄ *.csv          # ML datasets
‚îÇ   ‚îú‚îÄ‚îÄ *.db           # SQLite databases
‚îÇ   ‚îú‚îÄ‚îÄ chroma_db/     # Vector store
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_files/
‚îú‚îÄ‚îÄ jupyter_env/        # Python virtual environment
‚îú‚îÄ‚îÄ logs/              # Application logs
‚îú‚îÄ‚îÄ pdf/               # Reference materials
‚îú‚îÄ‚îÄ pptx/              # Lecture slides
‚îú‚îÄ‚îÄ tasks/             # Learning objectives
‚îú‚îÄ‚îÄ requirements.txt   # Python dependencies
‚îî‚îÄ‚îÄ README.md          # This file
```

---

## üöÄ Quick Start

### Option 1: Cloud (Easiest)
1. Open any notebook in Google Colab
2. Run the first cell to install dependencies
3. Follow along with the instructions

### Option 2: Local
```bash
# Clone repository
git clone https://github.com/yourusername/PGP-GABA.git
cd PGP-GABA

# Setup environment
python -m venv jupyter_env
source jupyter_env/bin/activate
pip install -r requirements.txt

# Launch Jupyter
jupyter notebook notebooks/
```

### Option 3: Local LLMs
```bash
# Install LM Studio from https://lmstudio.ai/
# Load a model (GPT-OSS 20B recommended)
# Start local server (default: http://localhost:1234)
# Run notebooks with "_GPTOSS" suffix
```

---

## üìö Additional Resources

### Documentation
- **`CLAUDE.md`** - Detailed architecture overview
- **`GPT_OSS_SETUP_README.md`** - Local LLM setup guide
- **`README_Mistral_Download.md`** - Mistral model instructions
- **`Lightweight_Model_Alternatives.md`** - Hardware compatibility guide

### Migration Guides
- **`V2_MIGRATION_SUMMARY.md`** - Version 2 updates
- **`FULLCODE_ENHANCEMENTS.md`** - Advanced features documentation
- **`FULLCODE_IMPLEMENTATION_PLAN.md`** - Development roadmap

---

## ü§ù Contributing

This is an educational repository. Feel free to:
- Report issues or typos
- Suggest improvements
- Share your project implementations
- Create variants for different use cases

---

## üìÑ License

Educational materials for the **Generative AI for Business Applications** program.  
¬© McCombs School of Business √ó Great Learning

---

## üéØ Key Differentiators

### Progressive Complexity
Each topic builds on previous knowledge with multiple variants:
- **Beginner**: Low-code, pre-built tools
- **Intermediate**: Full implementations with explanations
- **Advanced**: Production patterns, optimization, custom architectures

### Real Business Cases
Every notebook includes:
- Business context and objectives
- Industry-specific challenges
- ROI and impact metrics
- Deployment considerations

### Multi-Model Support
Compare and contrast:
- Cloud APIs (OpenAI GPT-4)
- Local models (GPT-OSS, Mistral, Phi-3.5, TinyLlama)
- Performance vs. cost trade-offs
- Mac/Windows/Linux compatibility

### Production-Ready Patterns
Learn not just theory, but:
- Error handling and retries
- Logging and observability
- Security and guardrails
- Scalability considerations
- Deployment strategies

---

<div align="center">

**Ready to master GenAI for business applications?**  
**Start with `02_PGP_GABA_Getting_Started_with_Python.ipynb`** üöÄ

</div>
