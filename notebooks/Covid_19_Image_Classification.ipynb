{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n",
        "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
        "</p></center>\n",
        "\n",
        "<center><font size=10>Generative AI for Business Applications</center></font>\n",
        "<center><font size=10> AI Foundations - DL</center></font>"
      ],
      "metadata": {
        "id": "dq3OlP-1_0vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://cdn.pixabay.com/photo/2020/03/16/16/29/virus-4937553_1280.jpg\" width=\"720\"/>\n",
        "</p></center>\n",
        "\n",
        "<center><font size=6>Covid-19 Image Classification</font></center>"
      ],
      "metadata": {
        "id": "dFUumBM9_55F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement"
      ],
      "metadata": {
        "id": "1MUVXiYXjALu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Context"
      ],
      "metadata": {
        "id": "IydRUQDSGNEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the resurgence of COVID-19 cases, health departments are facing increased pressure to quickly and accurately diagnose infections before they spread further. Traditional testing methods, such as PCR testing, often involve delays and require extensive resources, which can be a significant drawback during sudden surges in cases. Additionally, the reliance on these conventional methods can lead to bottlenecks in healthcare systems, especially in regions with limited testing facilities and resources. In response to these challenges, there is a growing need to harness innovative technologies to enhance early detection and management of the virus. Specifically, there is an imperative to develop a solution that leverages advanced analysis of chest X-ray images to rapidly detect COVID-19, thus enabling timely intervention and better allocation of healthcare resources.\n",
        "\n"
      ],
      "metadata": {
        "id": "IGSzS2xsYmgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective"
      ],
      "metadata": {
        "id": "HirXlWEYka1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary objective is to develop an AI-driven diagnostic system that analyzes chest X-ray images for early detection of COVID-19. The solution will use advanced image processing and machine learning techniques to accurately identify patterns and anomalies associated with COVID-19 infections. By doing so, the system aims to:\n",
        "- Accelerate the detection process, providing near real-time diagnostic insights to healthcare professionals.\n",
        "- Reduce the dependency on traditional testing methods, thereby minimizing delays and resource constraints.\n",
        "- Enhance the accuracy of early COVID-19 diagnosis, leading to more effective patient triage and treatment.\n",
        "- Support health departments in managing and responding to COVID-19 outbreaks more efficiently.\n",
        "\n",
        "Ultimately, this innovative approach will contribute to improved public health outcomes during the ongoing pandemic and better prepare health systems for future challenges."
      ],
      "metadata": {
        "id": "IX77JB_CGkxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description"
      ],
      "metadata": {
        "id": "TV5SxNQEkeGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains training set images of 2 classes which are converted into numpy arrays.\n",
        "\n",
        "\n",
        "**COVID-19:** The patient who is effected due to covid.\n",
        "\n",
        "**Normal:** A healthy Person with no symptoms of covid or fever.\n",
        "\n",
        "The data file names are:\n",
        "\n",
        "- CovidImages.npy\n",
        "\n",
        "- CovidLabels.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "2usp48o4kmt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Necessary Libraries"
      ],
      "metadata": {
        "id": "Jqa-DzIeie7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>I want to analyze the provided .npy data, build a neural network model to classify COVID images, and evaluate it using labeled classification data.\n",
        "Help me import the necessary Python libraries to\n",
        "1. Analyze the data\n",
        "2. Visualize patterns in the data\n",
        "3. Preprocess the data\n",
        "4. Build a neural network model to detect COVID cases from the input image data\n",
        "5. Evaluate the model's performance.\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "RM5RW5-0TopC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I want to analyze the provided .npy data, build a neural network model to classify COVID images, and evaluate it using labeled classification data.. Help me import the necessary Python libraries to\n",
        "# Analyze the data\n",
        "# Visualize patterns in the data\n",
        "# Preprocess the data\n",
        "# Build a neural network model to detect COVID cases from the input image data\n",
        "# Evaluate the model's performance.\n",
        "\n",
        "# Libraries for data analysis and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Libraries for image preprocessing\n",
        "import cv2\n",
        "\n",
        "# Libraries for building and evaluating the neural network model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout , Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "rrjrLVp_-SEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Set a random seed to 42 based on the libraries already imported to ensure consistent model results across multiple runs.\n",
        "</font>"
      ],
      "metadata": {
        "id": "ydhSsx_fUpOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "v2Qk4F7lHbj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting a random seed ensures that random processes like weight initialization and data shuffling give the same results every time, helping with consistent comparisons.\n"
      ],
      "metadata": {
        "id": "bMD6cv8k-Aks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Data"
      ],
      "metadata": {
        "id": "aQn6VQ5hIn1T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er-hahR_HS7L"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Mount the Google Drive\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yvmBPiheIm4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JhIr_HKrCN5"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Load the CovidImages.npy file and store it as images.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image file of the dataset\n",
        "images = np.load('/content/CovidImages.npy')\n"
      ],
      "metadata": {
        "id": "gJXnAETjgn6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNHevRQx-3R5"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Load the CovidLabels.csv file and store it as labels.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the labels file of the dataset\n",
        "labels = pd.read_csv('/content/CovidLabels.csv')"
      ],
      "metadata": {
        "id": "wZ8TmC8T-9Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Overview\n"
      ],
      "metadata": {
        "id": "imLbhd-DgvS7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQJ9sdmrNmmE"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Display the number of rows and columns in the images.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)"
      ],
      "metadata": {
        "id": "Fk_1B6gogvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Total Number of Images**: We have 251 individual images.\n",
        "\n",
        "- **Dimensions of Each Image**: Each image is 128 pixels wide and 128 pixels tall.\n",
        "\n",
        "- **Number of Channels**: Each image has 3 color channels, typically representing Red, Green, and Blue (RGB)."
      ],
      "metadata": {
        "id": "de8Q7LXNg0QI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOKI3a9_dNm"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Display the 5th image from the dataset\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[5])\n",
        "plt.title(labels.iloc[5, 0])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RzhW4yao_fPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "c6isEG2IiPR-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvUHfKiAD2Q"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Visualize 12 images from different labels in a 3×4 grid layout.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Visualize 12 images from different labels in a 3×4 grid layout.\n",
        "\n",
        "plt.figure(figsize=(12, 9))\n",
        "for i in range(12):\n",
        "  plt.subplot(3, 4, i+1)\n",
        "  plt.imshow(images[i*20]) # Select images with a gap of 20 to likely get different labels\n",
        "  plt.title(labels.iloc[i*20, 0])\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W5d9r7hL5HNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQAMF1AAAlAS"
      },
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Visualize the proportion of each label in the labels dataset\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Visualize the proportion of each label in the labels dataset\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Label', data=labels, palette='viridis')\n",
        "plt.title('Proportion of Each Label in the Dataset')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lykC8MvOAb5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "jpIxSBJmAXVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Map the Labels dataset with Covid as 1 and Normal as 0\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "uJHp8aLdxMin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels['Label'] = labels['Label'].map({'Covid': 1, 'Normal': 0})\n"
      ],
      "metadata": {
        "id": "DIRzq5vsFOTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Split the data into training, validation, and test sets in a 70:15:15 ratio\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "Pi66lWXwbFcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and temporary sets (70:30)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels['Label'], test_size=0.3, random_state=42, stratify=labels['Label'])\n",
        "\n",
        "# Split the temporary set into validation and test sets (15:15, which is 50:50 of the temp set)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "_6HgTuxHAyC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Normalization"
      ],
      "metadata": {
        "id": "d7xRHTbDiBmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing image data (scaling pixel values to a range between 0 and 1) is an essential preprocessing step before feeding it into a Convolutional Neural Network (CNN). This is done to ensure that all input features (pixel values) are on a similar scale, which helps the model train faster and more efficiently. Since raw pixel values range from 0 to 255, dividing by 255 brings them to the standard range that most CNNs expect.\n"
      ],
      "metadata": {
        "id": "CsQ4qMUV_PN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Normalize the image data.\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "6gnDHRgSDDDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the **image pixel values range from 0-255**, our method of normalization here will be **scaling** - we shall **divide all the pixel values by 255 to standardize the images to have values between 0-1.**"
      ],
      "metadata": {
        "id": "2Dw7a6d_ckbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Normalize the image data\n",
        "\n",
        "X_train_normalized = X_train / 255.0\n",
        "X_val_normalized = X_val / 255.0\n",
        "X_test_normalized = X_test / 255.0\n",
        "\n",
        "print(f\"Normalized training set min/max: {X_train_normalized.min()}/{X_train_normalized.max()}\")\n",
        "print(f\"Normalized validation set min/max: {X_val_normalized.min()}/{X_val_normalized.max()}\")\n",
        "print(f\"Normalized test set min/max: {X_test_normalized.min()}/{X_test_normalized.max()}\")\n"
      ],
      "metadata": {
        "id": "Q9JFLSs_CyIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "_IVrz_rGwK2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now train a Convolutional Neural Network (CNN) to classify images into two categories: COVID and Normal. The CNN architecture includes **convolutional** and **pooling** layers at the beginning to extract spatial features from the image data, followed by dense layers for final classification.\n",
        "\n",
        "Let’s briefly understand these key components:\n",
        "\n",
        "1. **Convolutional Layer**:\n",
        "   Applies filters to the input image to detect features like edges, textures, and patterns. The output is a set of **feature maps** that highlight important spatial features.\n",
        "\n",
        "2. **Pooling Layer (e.g., MaxPooling)**:\n",
        "   Reduces the spatial dimensions of the feature maps by selecting the maximum value in small regions (e.g., 2×2). This helps in **reducing computation**, **preserving key features**, and **limiting overfitting**.\n",
        "\n",
        "In this case study, we designed two CNN models with minor architectural differences to evaluate their impact on performance. Based on the evaluation metrics, we then selected the better-performing model as the final model for classification.\n"
      ],
      "metadata": {
        "id": "OoFJLvDj7yq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Reproducibility in CNN Results**\n",
        "\n",
        "*CNN results can vary across different runs due to random weight initialization, data shuffling during training, and non-deterministic GPU operations. These variations become more noticeable with small datasets, making it difficult to consistently reproduce the same results.*\n",
        "\n",
        "*You may observe **different outputs from the same inference code** in the notebook if the model is retrained each time.*\n",
        "\n",
        "*In practice, after training and selecting the final model for image classification, we **typically save the trained model**. This allows us to reuse the same model for future inference without retraining, ensuring consistent and stable results. However, in this notebook, the model is **not saved**, so the outputs may slightly differ across runs.*\n"
      ],
      "metadata": {
        "id": "7lZehs6SY4Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation Criteria"
      ],
      "metadata": {
        "id": "7Msz36Vb8uF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Overall Accuracy**\n",
        "   Measures the percentage of total correct predictions across both classes (COVID and Normal).\n",
        "\n",
        "   *Usefulness:* Provides a general view of how well the model is performing overall.\n",
        "\n",
        "2. **Recall for COVID Class**\n",
        "   Measures how well the model correctly identifies actual COVID-positive cases (True Positives / Actual Positives).\n",
        "\n",
        "   *Usefulness:* Crucial in medical settings to minimize false negatives and ensure COVID cases are not missed.\n"
      ],
      "metadata": {
        "id": "fRal8k04802e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Create an empty DataFrame `evaluation_result` to store the model name along with train accuracy, validation accuracy, train recall for COVID, and validation recall for COVID.\n",
        "\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "SdgJJyFf976r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create an empty DataFrame evaluation_result to store the model name along with train accuracy, validation accuracy, train recall for COVID, and validation recall for COVID.\n",
        "\n",
        "evaluation_result = pd.DataFrame(columns=['Model Name', 'Train Accuracy', 'Validation Accuracy', 'Train Recall (COVID)', 'Validation Recall (COVID)'])\n"
      ],
      "metadata": {
        "id": "6MKZnfeRAdbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model 1"
      ],
      "metadata": {
        "id": "9dro8NmH4T4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>  Reset any previously stored Keras model state and release system memory.\n",
        "</font>"
      ],
      "metadata": {
        "id": "_qu36hYlEGWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Clear Keras session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Garbage collect\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "KgzGTbzEEGWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Create a Convolutional neural network model for binary class image classification with the following architecture:\n",
        "- An input layer\n",
        "- 3 Combination of Convolutional and Pooling Layer\n",
        "- 1 hidden layer and ReLU activation\n",
        "- An output layer\n",
        "\n",
        "Use a relevant loss function, Adam as the optimizer, and accuracy as the metric to optimize for.\n",
        "Show the final model architecture with number of parameters and other details.\n",
        "</font>"
      ],
      "metadata": {
        "id": "2TSNMA2fGHTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create Convolutional neural network model for multiclass image classification with the following architecture:\n",
        "# An input layer\n",
        "# 3 Combination of Convolutional and Pooling Layer\n",
        "# 1 hidden layer and ReLU activation\n",
        "# An output layer\n",
        "# Use a relevant loss function, Adam as the optimizer with learning rate 0.0001, and accuracy as the metric to optimize for. Show the final model architecture with number of parameters and other details.\n",
        "\n",
        "model_cnn1 = Sequential([\n",
        "    Input(shape=(128, 128, 3)),\n",
        "\n",
        "    # First Combination of Convolutional and Pooling Layer\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Combination of Convolutional and Pooling Layer\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Combination 3: Conv + Pooling\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # Hidden layer with ReLU activation\n",
        "    Dense(128, activation='relu'),\n",
        "\n",
        "    # Output layer (using sigmoid for binary classification as per previous steps)\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model_cnn1.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy', # Using binary_crossentropy for binary classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_cnn1.summary()"
      ],
      "metadata": {
        "id": "raGN51W4ZkDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a short explanation of the hyperparameters used in CNN Layers:\n",
        "\n",
        "`Conv2D(32, (3, 3), activation='relu', padding='same')`\n",
        "\n",
        "* **32**: Number of filters (feature detectors) — the output will have 32 feature maps.\n",
        "* **(3, 3)**: Size of each filter — a 3×3 window slides over the input to capture patterns.\n",
        "* **activation='relu'**: Applies ReLU to introduce non-linearity and help learn complex features.\n",
        "* **padding='same'**: Keeps the output size the same as input by adding zero-padding around the edges.\n",
        "\n",
        "`MaxPooling2D((2, 2))`\n",
        "\n",
        "* **(2, 2)**: Pooling window size — takes the max value from each 2×2 block, reducing spatial dimensions by half (downsampling). Helps in reducing computation and controlling overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "tXQ1-vwA7Pwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Fit the model on the training data for 10 epochs with a batch size of 8, and record the training time.\n",
        "</font>"
      ],
      "metadata": {
        "id": "ZcNG8Pm4GmOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Fit the model on the training data for 25 epochs with a batch size of 32, and record the training time.\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model\n",
        "history = model_cnn1.fit(X_train_normalized, y_train,\n",
        "                        epochs=10,\n",
        "                        batch_size=8)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(f\"Training completed in {training_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "C8g1P53kGmOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Evaluate the performance of the model on the training and validation data, store it in evaluation_results and  display the report.\n",
        "</font>"
      ],
      "metadata": {
        "id": "Tk-QHUNsGmOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Evaluate the performance of the model on the training and validation data, store it in evaluation_results and display the report.\n",
        "\n",
        "# Evaluate on training data\n",
        "train_loss, train_acc = model_cnn1.evaluate(X_train_normalized, y_train, verbose=0)\n",
        "\n",
        "# Evaluate on validation data\n",
        "val_loss, val_acc = model_cnn1.evaluate(X_val_normalized, y_val, verbose=0)\n",
        "\n",
        "# Predict on training and validation data to get recall\n",
        "y_train_pred_prob = model_cnn1.predict(X_train_normalized)\n",
        "y_val_pred_prob = model_cnn1.predict(X_val_normalized)\n",
        "\n",
        "# Convert probabilities to binary predictions (assuming threshold of 0.5)\n",
        "y_train_pred = (y_train_pred_prob > 0.5).astype(int)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Get classification reports\n",
        "train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
        "val_report = classification_report(y_val, y_val_pred, output_dict=True)\n",
        "\n",
        "# Extract recall for the '1' class (which is 'Covid')\n",
        "train_recall_covid = train_report['1']['recall']\n",
        "val_recall_covid = val_report['1']['recall']\n",
        "\n",
        "# Append results to evaluation_result DataFrame using pd.concat\n",
        "new_row = pd.DataFrame([{\n",
        "    'Model Name': 'CNN Model (3 Conv Layers)',\n",
        "    'Train Accuracy': train_acc,\n",
        "    'Validation Accuracy': val_acc,\n",
        "    'Train Recall (COVID)': train_recall_covid,\n",
        "    'Validation Recall (COVID)': val_recall_covid\n",
        "}])\n",
        "evaluation_result = pd.concat([evaluation_result, new_row], ignore_index=True)\n",
        "\n",
        "# Display the evaluation report\n",
        "print(\"Evaluation Results:\")\n",
        "evaluation_result"
      ],
      "metadata": {
        "id": "eb5WDy6MKcpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "* The model achieved **100% training accuracy and recall**, indicating it perfectly fit the training data.\n",
        "* Validation accuracy was **97.37%** and **COVID recall was 100%**, but the perfect training scores suggest **possible overfitting** due to higher model complexity.\n"
      ],
      "metadata": {
        "id": "EG8LlV02tzRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model 2"
      ],
      "metadata": {
        "id": "JK0iZWHKFZvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To address the overfitting issue observed in the previous model, we made the following architectural and training tweaks:\n",
        "\n",
        "* **Reduced the number of Conv and MaxPooling layers** from 3 to 2 to lower model complexity.\n",
        "* **Decreased the learning rate** of the optimizer to **0.0001** for more stable and controlled training.\n",
        "* These changes aim to **prevent overfitting** and improve the model’s **generalization**.\n"
      ],
      "metadata": {
        "id": "jmHvir6zuAqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>  Reset any previously stored Keras model state and release system memory.\n",
        "</font>"
      ],
      "metadata": {
        "id": "NIN2rRKRFZvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Clear Keras session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Garbage collect\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "zGPVskowFZvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Create Convolutional neural network model for binary class image classification with the following architecture:\n",
        "- An input layer\n",
        "- 2 Combination of Convolutional and Pooling Layer\n",
        "- 1 hidden layer with ReLU activation\n",
        "- An output layer with 1 class\n",
        "\n",
        "Use a relevant loss function, Adam as the optimizer with learning rate 0.0001, and accuracy as the metric to optimize for.\n",
        "Show the final model architecture with number of parameters and other details.\n",
        "</font>"
      ],
      "metadata": {
        "id": "m8S6sslEFZvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Adam(learning_rate=0.0001)`\n",
        "\n",
        "We use a learning rate of **0.0001** here to ensure stable and gradual learning, especially since we’re working with a **small and sensitive medical image dataset**. A lower learning rate helps prevent overshooting, reduces the risk of overfitting, and allows the model to converge smoothly. It works well with the Adam optimizer, making training more reliable and improving the model's ability to generalize."
      ],
      "metadata": {
        "id": "J-ONilyKo-rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn2 = Sequential([\n",
        "    # Input layer\n",
        "    Input(shape=(X_train_normalized.shape[1], X_train_normalized.shape[2], X_train_normalized.shape[3])),\n",
        "\n",
        "    # Combination 1: Conv + Pooling\n",
        "    Conv2D(32, (3, 3), activation='relu',padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Combination 2: Conv + Pooling\n",
        "    Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten layer to transition from convolutional to dense layers\n",
        "    Flatten(),\n",
        "\n",
        "    # Hidden layer 1 with 64 neurons and ReLU activation\n",
        "    Dense(128, activation='relu'),\n",
        "\n",
        "    Dense(64,activation='relu'),\n",
        "\n",
        "    # Output layer with 3 neurons for 3 classes and softmax activation\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Define the Adam optimizer with the specified learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model\n",
        "model_cnn2.compile(optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Show model architecture and parameters\n",
        "model_cnn2.summary()"
      ],
      "metadata": {
        "id": "GSXJTYSqFZvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b> Fit the model on the training data for 25 epochs with a batch size of 32, and record the training time.\n",
        "</font>"
      ],
      "metadata": {
        "id": "Z9CpSNJiFZvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Fit the model on the training data for 25 epochs with a batch size of 32, and record the training time.\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit the model\n",
        "history = model_cnn2.fit(X_train_normalized, y_train,\n",
        "                        epochs=10,\n",
        "                        batch_size=8)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print(f\"Training completed in {training_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "HKCp1EV3FZvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Evaluate the performance of the model on the training and validation data, store it in evaluation_results and  display the report.\n",
        "</font>"
      ],
      "metadata": {
        "id": "tPyCSGRQFZvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Evaluate the performance of the model on the training and validation data, store it in evaluation_results and display the report.\n",
        "\n",
        "# Evaluate on training data\n",
        "train_loss, train_acc = model_cnn2.evaluate(X_train_normalized, y_train, verbose=0)\n",
        "\n",
        "# Evaluate on validation data\n",
        "val_loss, val_acc = model_cnn2.evaluate(X_val_normalized, y_val, verbose=0)\n",
        "\n",
        "# Predict on training and validation data to get recall\n",
        "y_train_pred_prob = model_cnn2.predict(X_train_normalized)\n",
        "y_val_pred_prob = model_cnn2.predict(X_val_normalized)\n",
        "\n",
        "# Convert probabilities to binary predictions (assuming threshold of 0.5)\n",
        "y_train_pred = (y_train_pred_prob > 0.5).astype(int)\n",
        "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Get classification reports\n",
        "train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
        "val_report = classification_report(y_val, y_val_pred, output_dict=True)\n",
        "\n",
        "# Extract recall for the '1' class (which is 'Covid')\n",
        "train_recall_covid = train_report['1']['recall']\n",
        "val_recall_covid = val_report['1']['recall']\n",
        "\n",
        "# Append results to evaluation_result DataFrame using pd.concat\n",
        "new_row = pd.DataFrame([{\n",
        "    'Model Name': 'CNN Model (2 Conv Layer)',\n",
        "    'Train Accuracy': train_acc,\n",
        "    'Validation Accuracy': val_acc,\n",
        "    'Train Recall (COVID)': train_recall_covid,\n",
        "    'Validation Recall (COVID)': val_recall_covid\n",
        "}])\n",
        "evaluation_result = pd.concat([evaluation_result, new_row], ignore_index=True)\n",
        "\n",
        "# Display the evaluation report\n",
        "print(\"Evaluation Results:\")\n",
        "evaluation_result"
      ],
      "metadata": {
        "id": "ATallAFBJvtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "* The model achieved **96% training accuracy** and **97.37% validation accuracy**, with strong **COVID recall on validation (94.1%)**, indicating effective classification.\n",
        "* Compared to the deeper model, it shows **better generalization** with no signs of overfitting, making it more robust for unseen data.\n",
        "* Its **simpler architecture** makes it more efficient while still maintaining high performance, suitable for small datasets.\n"
      ],
      "metadata": {
        "id": "VStJOtIstoBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The observations presented are based on the output obtained after training our model. However, please be aware that these results may vary when tried by others."
      ],
      "metadata": {
        "id": "hgnHRulsB458"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance Comparison and Final Model Selection"
      ],
      "metadata": {
        "id": "vi2j5UBzvY12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3-layer CNN model showed signs of overfitting with perfect training accuracy and recall, whereas the 2-layer CNN achieved similar validation performance with slightly lower training metrics, indicating better generalization on unseen data. Hence, we consider the **2-layer CNN (Model 2)** as our **final model**.\n"
      ],
      "metadata": {
        "id": "uWOf_4JtVA3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Performance"
      ],
      "metadata": {
        "id": "LQbeDqGIejiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Prompt***:\n",
        "\n",
        "<font size=3 color=\"#4682B4\"><b>Evaluate the model 2 on the test dataset\n",
        "</font>"
      ],
      "metadata": {
        "id": "dAwZSEnoG96c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Evaluate the model 2 on the test dataset\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model_cnn2.evaluate(X_test_normalized, y_test, verbose=0)\n",
        "\n",
        "# Predict on test data to get recall\n",
        "y_test_pred_prob = model_cnn2.predict(X_test_normalized)\n",
        "\n",
        "# Convert probabilities to binary predictions (assuming threshold of 0.5)\n",
        "y_test_pred = (y_test_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Get classification report for test data\n",
        "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "\n",
        "# Extract recall for the '1' class (which is 'Covid')\n",
        "test_recall_covid = test_report['1']['recall']\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Recall (COVID): {test_recall_covid:.4f}\")"
      ],
      "metadata": {
        "id": "7JYqJuSku3vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The final 2-layer CNN model achieved a **test accuracy of 97.37%** and a **COVID recall of 94.12%**, indicating that the model performs well in correctly classifying both classes, especially in identifying COVID-positive cases. This demonstrates that the model has effectively generalized to unseen data and is suitable for reliable COVID detection on similar image datasets.\n"
      ],
      "metadata": {
        "id": "E7IZfYxavH6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "9jTf0dEJ3mQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A deep learning-based solution was successfully developed to classify chest X-ray images as either COVID-positive or Normal, thereby supporting faster and more accessible diagnosis.\n",
        "\n",
        "- The proposed solution provides a rapid, cost-effective, and non-invasive diagnostic aid to assist radiologists in the early identification of COVID-19 from chest X-rays.\n",
        "\n",
        "- Future improvements may include expanding the dataset with a larger and more diverse set of images to further enhance the model’s robustness and generalizability.\n"
      ],
      "metadata": {
        "id": "4c6uplFdGW7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5.5 color=\"#4682B4\"><b>Power Ahead!</font>\n",
        "___"
      ],
      "metadata": {
        "id": "hfjwojnVgTii"
      }
    }
  ]
}